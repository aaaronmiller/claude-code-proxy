# Required: Your OpenAI API key
OPENAI_API_KEY="sk-your-openai-api-key-here"

# Optional: Expected Anthropic API key for client validation
# If set, clients must provide this exact API key to access the proxy
ANTHROPIC_API_KEY="your-expected-anthropic-api-key"

# Optional: OpenAI API base URL (default: https://api.openai.com/v1)
# You can change this to use other providers like Azure OpenAI, local models, etc.
OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Model mappings (BIG and SMALL models)
# BIG_MODEL="gpt-4o"
# Used for Claude opus requests
# MIDDLE_MODEL="gpt-4o"
# Used for Claude sonnet requests
# SMALL_MODEL="gpt-4o-mini"
# Used for Claude haiku requests

# Optional: GPT-5 reasoning configuration
# REASONING_EFFORT: Set to "low", "medium", or "high" to enable reasoning mode
# Default: not set (reasoning disabled unless explicitly enabled)
# Example: REASONING_EFFORT="high"
REASONING_EFFORT=""

# Optional: Verbosity setting for responses (affects detail level)
# Can be set to various levels depending on provider support
# Default: not set
# Example: VERBOSITY="high"
VERBOSITY=""

# Optional: Whether to exclude reasoning tokens from the response
# Set to "true" to hide reasoning tokens in the response
# Default: "false"
REASONING_EXCLUDE="false"

# Optional: Maximum tokens for reasoning (Anthropic/OpenRouter style)
# Set to an integer (e.g., 2000, 8000, 16000) for fine-grained control
# Works with reasoning-capable models (Anthropic, some OpenRouter models)
# Leave empty to use provider default
# Example: REASONING_MAX_TOKENS="8000"
REASONING_MAX_TOKENS=""

# Optional: Enable/disable OpenRouter model selection in interactive selector
# Set to "false" to hide OpenRouter marketplace models (only show local models)
# Default: "true" (show all models including OpenRouter)
# Example: ENABLE_OPENROUTER_SELECTION="false"
ENABLE_OPENROUTER_SELECTION="true"

# ═══════════════════════════════════════════════════════════════════════════════
# HYBRID MODE - Optional per-model routing (mix local and remote models!)
# ═══════════════════════════════════════════════════════════════════════════════

# Enable per-model routing for BIG model (Claude Opus)
# Set to "true" to enable custom endpoint for BIG model
# Example: ENABLE_BIG_ENDPOINT="true"
ENABLE_BIG_ENDPOINT="false"

# BIG model endpoint URL (if enabled above)
# Example: BIG_ENDPOINT="http://localhost:11434/v1"
BIG_ENDPOINT="https://api.openai.com/v1"

# BIG model API key (if enabled above, defaults to OPENAI_API_KEY if not set)
# Example: BIG_API_KEY="sk-or-..."
BIG_API_KEY=""

# Enable per-model routing for MIDDLE model (Claude Sonnet)
# Set to "true" to enable custom endpoint for MIDDLE model
# Example: ENABLE_MIDDLE_ENDPOINT="true"
ENABLE_MIDDLE_ENDPOINT="false"

# MIDDLE model endpoint URL (if enabled above)
# Example: MIDDLE_ENDPOINT="https://openrouter.ai/api/v1"
MIDDLE_ENDPOINT="https://api.openai.com/v1"

# MIDDLE model API key (if enabled above, defaults to OPENAI_API_KEY if not set)
# Example: MIDDLE_API_KEY="sk-or-..."
MIDDLE_API_KEY=""

# Enable per-model routing for SMALL model (Claude Haiku)
# Set to "true" to enable custom endpoint for SMALL model
# Example: ENABLE_SMALL_ENDPOINT="true"
ENABLE_SMALL_ENDPOINT="false"

# SMALL model endpoint URL (if enabled above)
# Example: SMALL_ENDPOINT="http://127.0.0.1:1234/v1"
SMALL_ENDPOINT="https://api.openai.com/v1"

# SMALL model API key (if enabled above, defaults to OPENAI_API_KEY if not set)
# Example: SMALL_API_KEY="sk-or-..."
SMALL_API_KEY=""

# Optional: Server settings
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="INFO"  
# DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Performance settings  
MAX_TOKENS_LIMIT="4096"
# Minimum tokens limit for requests (to avoid errors with thinking model)
MIN_TOKENS_LIMIT="4096"
REQUEST_TIMEOUT="90"
MAX_RETRIES="2"

# Examples for other providers:

# For Azure OpenAI (recommended if OpenAI is not available in your region):
# OPENAI_API_KEY="your-azure-api-key"
# OPENAI_BASE_URL="https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name"
# AZURE_API_VERSION="2024-03-01-preview"
# BIG_MODEL="gpt-4"
# MIDDLE_MODEL="gpt-4"
# SMALL_MODEL="gpt-35-turbo"

# For local models (like Ollama):
# OPENAI_API_KEY="dummy-key"  # Required but can be any value for local models
# OPENAI_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL="llama3.1:70b"
# MIDDLE_MODEL="llama3.1:70b"
# SMALL_MODEL="llama3.1:8b"

# Note: If you get "unsupported_country_region_territory" errors,
# consider using Azure OpenAI or a local model setup instead.
