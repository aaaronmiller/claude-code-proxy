# ═══════════════════════════════════════════════════════════════════════════════
# CLAUDE CODE PROXY - ENVIRONMENT CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════
# Copy this file to .env and fill in your values

# ─────────────────────────────────────────────────────────────────────────────
# PRIMARY PROVIDER (Required)
# ─────────────────────────────────────────────────────────────────────────────
# OpenRouter (recommended for multi-model access)
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Or use a specific provider:
# OPENAI_API_KEY=sk-your-key-here
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Provider endpoint (auto-detected from key if not set)
# OPENAI_BASE_URL=https://openrouter.ai/api/v1

# ─────────────────────────────────────────────────────────────────────────────
# MODEL CONFIGURATION
# ─────────────────────────────────────────────────────────────────────────────
# Default models for each tier
BIG_MODEL=anthropic/claude-sonnet-4-20250514
MIDDLE_MODEL=google/gemini-2.0-flash-001
SMALL_MODEL=google/gemini-2.0-flash-001

# ─────────────────────────────────────────────────────────────────────────────
# MODEL CASCADE (Automatic fallback on errors)
# ─────────────────────────────────────────────────────────────────────────────
# Enable cascade: tries fallback models on SSL/connection/rate errors
# MODEL_CASCADE=true

# Comma-separated fallback models (provider/model format)
# BIG_CASCADE=openai/gpt-4o,anthropic/claude-3-opus,google/gemini-pro
# MIDDLE_CASCADE=openai/gpt-4o-mini,anthropic/claude-3-sonnet
# SMALL_CASCADE=openai/gpt-4o-mini,google/gemini-flash

# ─────────────────────────────────────────────────────────────────────────────
# PER-ENDPOINT OVERRIDES (Optional)
# ─────────────────────────────────────────────────────────────────────────────
# Enable per-model endpoints for routing to different providers
# ENABLE_BIG_ENDPOINT=true
# BIG_ENDPOINT=http://127.0.0.1:8317/v1
# BIG_API_KEY=your-vibeproxy-key

# ENABLE_MIDDLE_ENDPOINT=true
# MIDDLE_ENDPOINT=https://openrouter.ai/api/v1
# MIDDLE_API_KEY=sk-or-v1-your-key

# ENABLE_SMALL_ENDPOINT=true
# SMALL_ENDPOINT=https://openrouter.ai/api/v1
# SMALL_API_KEY=sk-or-v1-your-key

# ─────────────────────────────────────────────────────────────────────────────
# SERVER SETTINGS
# ─────────────────────────────────────────────────────────────────────────────
HOST=0.0.0.0
PORT=8082

# ─────────────────────────────────────────────────────────────────────────────
# FEATURES
# ─────────────────────────────────────────────────────────────────────────────
ENABLE_DASHBOARD=true
TRACK_USAGE=true

# ─────────────────────────────────────────────────────────────────────────────
# MODEL RANKING & SCRAPING (Optional)
# ─────────────────────────────────────────────────────────────────────────────
# Model used for AI-powered ranking and scraping (defaults to free models)
# SCRAPER_MODEL=kwaicoder/kwaicoder-ds-v1
# RANKER_MODEL=kwaicoder/kwaicoder-ds-v1

# Enable web search for more accurate model rankings
# Requires Exa API key: https://exa.ai
EXA_API_KEY=your-exa-api-key-here

# Enable/disable web search for ranking (default: true if EXA_API_KEY is set)
# RANKER_USE_SEARCH=true

# ─────────────────────────────────────────────────────────────────────────────
# REASONING / THINKING
# ─────────────────────────────────────────────────────────────────────────────
# REASONING_EFFORT=medium
# REASONING_EXCLUDE=false

# ─────────────────────────────────────────────────────────────────────────────
# ADVANCED
# ─────────────────────────────────────────────────────────────────────────────
# LOG_LEVEL=info
# PASSTHROUGH_MODE=false
